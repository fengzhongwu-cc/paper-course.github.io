## 20. End-To-End Memory Networks

### 20.1 第一课时

<video width=80%  controls >
	<source type="video/mp4" src="020-end-to-end-memory-networks/020-1.mp4">
</video>

**任务名称：**了解记忆网络的概念，了解RNN序列模型以及它的两种变体GRU和LSTM。

**任务简介：**观看视频第一课时，阅读论文

**任务详解：**

1. 视频第一课时
   1. 记忆网络的概念

      记忆网络就是设计模块来存储序列模型的中间结果以防丢失信息。

   2. 普通的RNN模型以及其变种GRU和LSTM

      最常用的序列模型就是RNN模型以及它的两种变体GRU和LSTM，希望大家了解RNN模型并比较其与记忆网络的区别。

   2. 了解记忆网络

      记忆网络最先提出了2014年Facebook的Memory Networks这篇文章，希望大家了解一下这种文章提出的记忆网络。

2. 论文阅读

   花费大致2h来阅读论文，主要通过阅读了解模型的大致结构，将疑问记录在作业中。

   这个部分我们只需要比较熟悉地了解到导读视频的程度，不需要过于深入地去学习，将重点放置在论文的模型上，对于其他的部分有疑问可以暂时记录着，并写在这两天的作业中。

**论文及代码下载地址：**

链接：https://pan.baidu.com/s/1mLmEbs-KUlt4oEjPDH0GHQ 

提取码：smbu

**打卡要求：**（形式：文字，字数至少100）总结三种RNN模型以及最初的记忆网络方法。

### 20.2 第二课时

<video width=80%  controls >
	<source type="video/mp4" src="020-end-to-end-memory-networks/020-2.mp4">
</video>

**任务名称：**进一步了解论文中的端对端记忆网络模型的部分细节，从理论掌握模型结构，论文中的技巧

**任务简介：**观看视频第二课时，阅读论文

**任务详解：**

1. 视频
   1. 上节回顾

      回顾上节讲的RNN序列模型以及记忆网络的相关概念。

   2. 最初的非端对端记忆网络

      理解2014年Facebook的非端对端记忆网络。
      
   3. 论文提出的模型以及实验结果
   
      深入理解论文提出的端对端记忆网络模型，并查看实验结果。

2. 阅读论文

   先自己尝试观看本次论文，然后在看视频进一步解决自己的困惑并加强理解本篇论文。

**打卡要求：**（形式：文字或者图片，字数至少100）

1. 本文如何处理问题和背景文本之间的交互？

2. 本文如何处理词序之间的信息以及句子与句子之间的顺序信息？

3. 本文如何将端对端的记忆网络分别用于QA和语言模型两种任务？

### 20.3 第三课时

<video width=80%  controls >
	<source type="video/mp4" src="020-end-to-end-memory-networks/020-3.mp4">
</video>

**任务名称：**代码实践的方法与流程，讲解论文提出的模型的tensorflow实现

**任务简介：**观看视频第三课时，跑通提供的代码，调整网络结构减低困惑度

**任务详解：**

1. 视频
   1. 数据处理方法

      本文的数据处理是针对语言模型，大家可以学习一下语言模型的输入输出处理。

   2. 模型的构建

      使用tensorflow构建整个模型，理解其中各个embedding的含义以及hop中的处理。

   3. 训练和测试

      利用构建好的模型在以及处理好的数据上进行训练和测试并验证试验结果。

   4. 调整超参提高准确率

      通过调整超参查看模型的准确率是否能够一直提高。

**打卡要求：**（形式：图片）

1. 开源自己的tensorflow (其他框架均可以)实现。

2. 在语言模型数据集上的实验结果并截图。

3. 试图提高模型在测试集上的结果。

**论文及代码下载地址：**

链接：https://pan.baidu.com/s/1mLmEbs-KUlt4oEjPDH0GHQ 

提取码：smbu