<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context | PAPER COURSE</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="https://paper-course.github.io/" />
<meta property="og:description" content="https://paper-course.github.io/" />
<link rel="canonical" href="https://paper-course.github.io/nlp/027-attentive-language-models-beyond-a-fixed-length-context.html" />
<meta property="og:url" content="https://paper-course.github.io/nlp/027-attentive-language-models-beyond-a-fixed-length-context.html" />
<meta property="og:site_name" content="PAPER COURSE" />
<script type="application/ld+json">
{"@type":"WebPage","url":"https://paper-course.github.io/nlp/027-attentive-language-models-beyond-a-fixed-length-context.html","description":"https://paper-course.github.io/","headline":"Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=467592b0d89ce5efa193e96aee5c5f078b1a2c96">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">PAPER COURSE</h1>
      <h2 class="project-tagline">https://paper-course.github.io/</h2>
      
      
    </section>

    <section class="main-content">
      <h2 id="27-transformer-xl-attentive-language-models-beyond-a-fixed-length-context">27. Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</h2>

<h3 id="271-第一课时">27.1 第一课时</h3>

<video width=80%  controls >
	<source type="video/mp4" src="027-attentive-language-models-beyond-a-fixed-length-context/027-1.mp4" />
</video>

<p><strong>任务名称：</strong>了解RNN、Transformer</p>

<p><strong>任务简介：</strong>观看视频第一课时，阅读论文</p>

<p><strong>任务详解：</strong>这个部分我们需要比较熟悉地了解到导读视频的程度，掌握Transformer的架构和计算公式，不需要过于深入地去学习，论文中有疑问的部分可以先记录着。</p>

<ol>
  <li>
    <p>视频第一课时</p>

    <ol>
      <li>
        <p>RNN</p>

        <p>RNN及其变种是NLP中常用的序列建模方法。受限于其无法并行以及无法建模长距离的限制，目前已逐渐被Transformer取代。</p>
      </li>
      <li>
        <p>Transformer</p>

        <p>Transformer是目前最火热的序列建模方法，掌握其具体的架构以及多头自注意力机制的计算方法</p>
      </li>
    </ol>
  </li>
  <li>
    <p>论文阅读</p>

    <p>花费大致2h来阅读论文，主要通过阅读了解模型的大致结构，将疑问记录在作业中。</p>
  </li>
</ol>

<p><strong>论文原文下载：</strong></p>

<p>链接：https://pan.baidu.com/s/1dHh_myBwA4YLPzgC90vwwg</p>

<p>提取码：3x6q</p>

<p><strong>打卡要求：</strong>（形式：文字，字数至少100）按照自己的理解总结上述知识点（最好分点清晰，有树状的层次结构，必要时推导公式）。</p>

<h3 id="272-第二课时">27.2 第二课时</h3>

<video width=80%  controls >
	<source type="video/mp4" src="027-attentive-language-models-beyond-a-fixed-length-context/027-2.mp4" />
</video>

<p><strong>任务名称：</strong>学习阅读论文的方法，进一步了解经典模型的部分细节，从理论掌握模型结构，论文中的技巧</p>

<p><strong>任务简介：</strong>观看视频第二课时，阅读论文</p>

<p><strong>任务详解：</strong></p>

<ol>
  <li>
    <p>视频</p>

    <ol>
      <li>
        <p>了解Transformer-XL模型的细节</p>

        <p>对比Transformer，XL在建模多个segment之间的依赖关系上进行了改进。同时改进了相对位置编码方式。阅读论文</p>
      </li>
    </ol>
  </li>
  <li>
    <p>在学习完视频之后再阅读论文，看看自己是不是能了然于胸，对照课程PPT阅读，记录疑问</p>
  </li>
</ol>

<p><strong>任务详解：</strong>这个部分我们需要能够理解模型的设计细节以及动机，并掌握XL与Transformer的异同。</p>

<p><strong>打卡要求：</strong>（形式：文字或者图片，字数至少100）</p>

<ol>
  <li>回答下列问题：
    <ol>
      <li>建模多个segment之间的依赖关系，还有哪些方式？</li>
      <li>阅读XLNet，XLNet在XL的基础上，又加入了哪些部分？</li>
    </ol>
  </li>
</ol>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
