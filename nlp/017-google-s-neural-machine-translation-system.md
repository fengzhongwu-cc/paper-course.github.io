## 17. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation

### 17.1 第一课时

<video width=80%  controls >
	<source type="video/mp4" src="017-google-s-neural-machine-translation-system/017-1.mp4">
</video>

**任务名称：**了解神经机器翻译的概念，了解三种不同的神经机器翻译模型。

**任务简介：**观看视频第一课时，阅读论文

**任务详解：**

1. 视频第一课时

   1. 神经机器翻译的概念

      神经机器翻译就是通过端对端的神经网络使得机器能够自动将一种语言的句子翻译成另外一种语言的句子。

   2. 三种神经机器翻译模型

      了解基于多层LSTM、attention、处理OOV词的三种神经机器翻译模型。

   3. 了解Seq2Seq模型

      当前的神经机器翻译模型都是基于端对端的Seq2Seq结果，包含一个Encoder和一个Decoder，Encoder将源语言压缩成一个向量，而Decoder利用源语言压缩得到的向量生成目标句子。

2. 论文阅读

   花费大致2h来阅读论文，主要通过阅读了解模型的大致结构，将疑问记录在作业中。

   这个部分我们只需要比较熟悉地了解到导读视频的程度，不需要过于深入地去学习，将重点放置在论文的模型上，对于其他的部分有疑问可以暂时记录着，并写在这两天的作业中。

**打卡要求：**（形式：文字，字数至少100）总结三种RNN模型以及最初的记忆网络方法。

### 17.2 第二课时

<video width=80%  controls >
	<source type="video/mp4" src="017-google-s-neural-machine-translation-system/017-2.mp4">
</video>

**任务名称：**进一步了解论文中的谷歌的神经机器翻译系统的细节，从理论掌握模型结构，论文中的技巧

**任务简介：**观看视频第二课时，阅读论文

**任务详解：**

1. 视频

   1. 上节回顾

      回顾上节讲的神经机器翻译模型的概率以及三种不同结构的神经机器翻译模型。

   2. 谷歌的神经机器翻译系统

      理解谷歌神经机器翻译系统的细节，包括模型的总体结构，attention，残差连接，底层的双向LSTM以及改进的Beam Search等。

   3. 谷歌神经机器翻译系统实验结果

      深入理解论文突出的谷歌神经机器系统的实验结果。

2. 阅读论文

   先自己尝试观看本次论文，然后在看视频进一步解决自己的困惑并加强理解本篇论文。

打卡要求：（形式：文字或者图片，字数至少100）

1. 谷歌的神经机器翻译系统如何处理梯度消失？

2. 谷歌的神经机器翻译中Beam Search函数的意义？

3. 谷歌的神经机器翻译系统是否超越了人类的翻译水平？